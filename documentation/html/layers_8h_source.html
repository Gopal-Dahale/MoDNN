<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.0 Transitional//EN" "http://www.w3.org/TR/xhtml1/DTD/xhtml1-transitional.dtd">
<html xmlns="http://www.w3.org/1999/xhtml">
<head>
<meta http-equiv="Content-Type" content="text/xhtml;charset=UTF-8"/>
<meta http-equiv="X-UA-Compatible" content="IE=9"/>
<meta name="generator" content="Doxygen 1.8.11"/>
<title>MoDNN: layers/layers.h Source File</title>
<link href="tabs.css" rel="stylesheet" type="text/css"/>
<script type="text/javascript" src="jquery.js"></script>
<script type="text/javascript" src="dynsections.js"></script>
<link href="search/search.css" rel="stylesheet" type="text/css"/>
<script type="text/javascript" src="search/searchdata.js"></script>
<script type="text/javascript" src="search/search.js"></script>
<script type="text/javascript">
  $(document).ready(function() { init_search(); });
</script>
<link href="doxygen.css" rel="stylesheet" type="text/css" />
</head>
<body>
<div id="top"><!-- do not remove this div, it is closed by doxygen! -->
<div id="titlearea">
<table cellspacing="0" cellpadding="0">
 <tbody>
 <tr style="height: 56px;">
  <td id="projectalign" style="padding-left: 0.5em;">
   <div id="projectname">MoDNN
   </div>
  </td>
 </tr>
 </tbody>
</table>
</div>
<!-- end header part -->
<!-- Generated by Doxygen 1.8.11 -->
<script type="text/javascript">
var searchBox = new SearchBox("searchBox", "search",false,'Search');
</script>
  <div id="navrow1" class="tabs">
    <ul class="tablist">
      <li><a href="index.html"><span>Main&#160;Page</span></a></li>
      <li><a href="pages.html"><span>Related&#160;Pages</span></a></li>
      <li><a href="namespaces.html"><span>Namespaces</span></a></li>
      <li><a href="annotated.html"><span>Data&#160;Structures</span></a></li>
      <li class="current"><a href="files.html"><span>Files</span></a></li>
      <li>
        <div id="MSearchBox" class="MSearchBoxInactive">
        <span class="left">
          <img id="MSearchSelect" src="search/mag_sel.png"
               onmouseover="return searchBox.OnSearchSelectShow()"
               onmouseout="return searchBox.OnSearchSelectHide()"
               alt=""/>
          <input type="text" id="MSearchField" value="Search" accesskey="S"
               onfocus="searchBox.OnSearchFieldFocus(true)" 
               onblur="searchBox.OnSearchFieldFocus(false)" 
               onkeyup="searchBox.OnSearchFieldChange(event)"/>
          </span><span class="right">
            <a id="MSearchClose" href="javascript:searchBox.CloseResultsWindow()"><img id="MSearchCloseImg" border="0" src="search/close.png" alt=""/></a>
          </span>
        </div>
      </li>
    </ul>
  </div>
  <div id="navrow2" class="tabs2">
    <ul class="tablist">
      <li><a href="files.html"><span>File&#160;List</span></a></li>
      <li><a href="globals.html"><span>Globals</span></a></li>
    </ul>
  </div>
<!-- window showing the filter options -->
<div id="MSearchSelectWindow"
     onmouseover="return searchBox.OnSearchSelectShow()"
     onmouseout="return searchBox.OnSearchSelectHide()"
     onkeydown="return searchBox.OnSearchSelectKey(event)">
</div>

<!-- iframe showing the search results (closed by default) -->
<div id="MSearchResultsWindow">
<iframe src="javascript:void(0)" frameborder="0" 
        name="MSearchResults" id="MSearchResults">
</iframe>
</div>

<div id="nav-path" class="navpath">
  <ul>
<li class="navelem"><a class="el" href="dir_56f60c3eea91268671faf82814ce7b6d.html">layers</a></li>  </ul>
</div>
</div><!-- top -->
<div class="header">
  <div class="headertitle">
<div class="title">layers.h</div>  </div>
</div><!--header-->
<div class="contents">
<a href="layers_8h.html">Go to the documentation of this file.</a><div class="fragment"><div class="line"><a name="l00001"></a><span class="lineno">    1</span>&#160;<span class="preprocessor">#ifndef LAYER_H_</span></div><div class="line"><a name="l00002"></a><span class="lineno">    2</span>&#160;<span class="preprocessor">#define LAYER_H_</span></div><div class="line"><a name="l00003"></a><span class="lineno">    3</span>&#160;</div><div class="line"><a name="l00004"></a><span class="lineno">    4</span>&#160;<span class="preprocessor">#include &quot;../vmm/vmm.h&quot;</span></div><div class="line"><a name="l00005"></a><span class="lineno">    5</span>&#160;<span class="preprocessor">#include &lt;cudnn.h&gt;</span></div><div class="line"><a name="l00006"></a><span class="lineno">    6</span>&#160;<span class="preprocessor">#include &lt;vector&gt;</span></div><div class="line"><a name="l00007"></a><span class="lineno">    7</span>&#160;<span class="preprocessor">#include &lt;queue&gt;</span></div><div class="line"><a name="l00008"></a><span class="lineno">    8</span>&#160;<span class="preprocessor">#include &lt;string&gt;</span></div><div class="line"><a name="l00009"></a><span class="lineno">    9</span>&#160;<span class="preprocessor">#include &lt;iostream&gt;</span></div><div class="line"><a name="l00010"></a><span class="lineno">   10</span>&#160;<span class="preprocessor">#include &lt;sstream&gt;</span></div><div class="line"><a name="l00011"></a><span class="lineno">   11</span>&#160;<span class="preprocessor">#include &lt;map&gt;</span></div><div class="line"><a name="l00012"></a><span class="lineno">   12</span>&#160;<span class="preprocessor">#include &lt;cublas_v2.h&gt;</span></div><div class="line"><a name="l00013"></a><span class="lineno">   13</span>&#160;<span class="preprocessor">#include &lt;cassert&gt;</span></div><div class="line"><a name="l00014"></a><span class="lineno">   14</span>&#160;<span class="preprocessor">#include &lt;cstdlib&gt;</span></div><div class="line"><a name="l00015"></a><span class="lineno">   15</span>&#160;<span class="preprocessor">#include &lt;random&gt;</span></div><div class="line"><a name="l00016"></a><span class="lineno">   16</span>&#160;<span class="preprocessor">#include &lt;cuda.h&gt;</span></div><div class="line"><a name="l00017"></a><span class="lineno">   17</span>&#160;<span class="preprocessor">#include &lt;fstream&gt;</span></div><div class="line"><a name="l00018"></a><span class="lineno">   18</span>&#160;</div><div class="line"><a name="l00019"></a><span class="lineno"><a class="line" href="layers_8h.html#a2527f5d1bfa5229f57083db0d82f54be">   19</a></span>&#160;<span class="keyword">enum</span> <a class="code" href="layers_8h.html#a2527f5d1bfa5229f57083db0d82f54be">padding_type</a>{</div><div class="line"><a name="l00020"></a><span class="lineno"><a class="line" href="layers_8h.html#a2527f5d1bfa5229f57083db0d82f54bea57316ad3090cf5cb9a92a3ec55dc18e9">   20</a></span>&#160;  <a class="code" href="layers_8h.html#a2527f5d1bfa5229f57083db0d82f54bea57316ad3090cf5cb9a92a3ec55dc18e9">SAME</a>,</div><div class="line"><a name="l00021"></a><span class="lineno"><a class="line" href="layers_8h.html#a2527f5d1bfa5229f57083db0d82f54beacf0713491d9b887eaccfd80c18abca47">   21</a></span>&#160;  <a class="code" href="layers_8h.html#a2527f5d1bfa5229f57083db0d82f54beacf0713491d9b887eaccfd80c18abca47">VALID</a></div><div class="line"><a name="l00022"></a><span class="lineno">   22</span>&#160;};</div><div class="line"><a name="l00023"></a><span class="lineno">   23</span>&#160;</div><div class="line"><a name="l00024"></a><span class="lineno">   24</span>&#160;</div><div class="line"><a name="l00025"></a><span class="lineno"><a class="line" href="layers_8h.html#a09bc9e6a44f0291cfcf578f2efcddfab">   25</a></span>&#160;<span class="preprocessor">#define MU 0</span></div><div class="line"><a name="l00026"></a><span class="lineno"><a class="line" href="layers_8h.html#ab899f53048f1f06a224b5eb1fa369750">   26</a></span>&#160;<span class="preprocessor">#define SIGMA 0.1</span></div><div class="line"><a name="l00027"></a><span class="lineno"><a class="line" href="layers_8h.html#a3572ba4e929ec4380493fcfbbde0efa2">   27</a></span>&#160;<span class="preprocessor">#define LR 0.0001</span></div><div class="line"><a name="l00028"></a><span class="lineno"><a class="line" href="layers_8h.html#a9ae2958e436c566413867028fc829ec0">   28</a></span>&#160;<span class="preprocessor">#define BATCH_SIZE 128</span></div><div class="line"><a name="l00029"></a><span class="lineno"><a class="line" href="layers_8h.html#a62ecd70800687eb2d625af180c4210d7">   29</a></span>&#160;<span class="preprocessor">#define TILE_SIZE  32</span></div><div class="line"><a name="l00030"></a><span class="lineno"><a class="line" href="layers_8h.html#ad51ded0bbd705f02f73fc60c0b721ced">   30</a></span>&#160;<span class="preprocessor">#define BLOCK_SIZE 8</span></div><div class="line"><a name="l00031"></a><span class="lineno">   31</span>&#160;</div><div class="line"><a name="l00032"></a><span class="lineno">   32</span>&#160;</div><div class="line"><a name="l00033"></a><span class="lineno"><a class="line" href="layers_8h.html#acf27caf7ab6bdde4b9a8a8f6998c9212">   33</a></span>&#160;<span class="preprocessor">#define checkCUDNN(expression)                               \</span></div><div class="line"><a name="l00034"></a><span class="lineno">   34</span>&#160;<span class="preprocessor">  {                                                          \</span></div><div class="line"><a name="l00035"></a><span class="lineno">   35</span>&#160;<span class="preprocessor">    cudnnStatus_t status = (expression);                     \</span></div><div class="line"><a name="l00036"></a><span class="lineno">   36</span>&#160;<span class="preprocessor">    if (status != CUDNN_STATUS_SUCCESS) {                    \</span></div><div class="line"><a name="l00037"></a><span class="lineno">   37</span>&#160;<span class="preprocessor">      std::cerr &lt;&lt; &quot;Error on line &quot; &lt;&lt; __LINE__ &lt;&lt; &quot;: &quot;      \</span></div><div class="line"><a name="l00038"></a><span class="lineno">   38</span>&#160;<span class="preprocessor">                &lt;&lt; cudnnGetErrorString(status) &lt;&lt; std::endl; \</span></div><div class="line"><a name="l00039"></a><span class="lineno">   39</span>&#160;<span class="preprocessor">      std::exit(EXIT_FAILURE);                               \</span></div><div class="line"><a name="l00040"></a><span class="lineno">   40</span>&#160;<span class="preprocessor">    }                                                        \</span></div><div class="line"><a name="l00041"></a><span class="lineno">   41</span>&#160;<span class="preprocessor">  }</span></div><div class="line"><a name="l00042"></a><span class="lineno">   42</span>&#160;</div><div class="line"><a name="l00043"></a><span class="lineno">   43</span>&#160;<span class="keyword">const</span> <span class="keywordtype">char</span> *<a class="code" href="layers_8h.html#af73fa246eea18b9cf1297ec23452622b">cublasGetErrorString</a>(cublasStatus_t error);</div><div class="line"><a name="l00044"></a><span class="lineno">   44</span>&#160;</div><div class="line"><a name="l00045"></a><span class="lineno"><a class="line" href="layers_8h.html#a47412fa74e50c6d8667b4a71ebaf2f67">   45</a></span>&#160;<span class="preprocessor">#define checkCUBLAS(expression)                              \</span></div><div class="line"><a name="l00046"></a><span class="lineno">   46</span>&#160;<span class="preprocessor">  {                                                          \</span></div><div class="line"><a name="l00047"></a><span class="lineno">   47</span>&#160;<span class="preprocessor">    cublasStatus_t status = (expression);                     \</span></div><div class="line"><a name="l00048"></a><span class="lineno">   48</span>&#160;<span class="preprocessor">    if (status != CUBLAS_STATUS_SUCCESS) {                    \</span></div><div class="line"><a name="l00049"></a><span class="lineno">   49</span>&#160;<span class="preprocessor">      std::cerr &lt;&lt; &quot;Error on line &quot; &lt;&lt; __LINE__ &lt;&lt; &quot;: &quot;      \</span></div><div class="line"><a name="l00050"></a><span class="lineno">   50</span>&#160;<span class="preprocessor">                &lt;&lt; cublasGetErrorString(status) &lt;&lt; std::endl; \</span></div><div class="line"><a name="l00051"></a><span class="lineno">   51</span>&#160;<span class="preprocessor">      std::exit(EXIT_FAILURE);                               \</span></div><div class="line"><a name="l00052"></a><span class="lineno">   52</span>&#160;<span class="preprocessor">    }                                                        \</span></div><div class="line"><a name="l00053"></a><span class="lineno">   53</span>&#160;<span class="preprocessor">  }</span></div><div class="line"><a name="l00054"></a><span class="lineno">   54</span>&#160;</div><div class="line"><a name="l00055"></a><span class="lineno">   55</span>&#160;</div><div class="line"><a name="l00056"></a><span class="lineno"><a class="line" href="layers_8h.html#a3f6ea8e9ef58125936d50d7e1181aa7a">   56</a></span>&#160;<span class="preprocessor">#define gpuErrchk(ans) { gpuAssert((ans), __FILE__, __LINE__); }</span></div><div class="line"><a name="l00057"></a><span class="lineno"><a class="line" href="layers_8h.html#ab3e90881a2476fd461eb2bcfcaa7cf63">   57</a></span>&#160;<span class="keyword">inline</span> <span class="keywordtype">void</span> <a class="code" href="layers_8h.html#ab3e90881a2476fd461eb2bcfcaa7cf63">gpuAssert</a>(cudaError_t code, <span class="keyword">const</span> <span class="keywordtype">char</span> *file, <span class="keywordtype">int</span> line, <span class="keywordtype">bool</span> abort=<span class="keyword">true</span>)</div><div class="line"><a name="l00058"></a><span class="lineno">   58</span>&#160;{</div><div class="line"><a name="l00059"></a><span class="lineno">   59</span>&#160;   <span class="keywordflow">if</span> (code != cudaSuccess)</div><div class="line"><a name="l00060"></a><span class="lineno">   60</span>&#160;   {</div><div class="line"><a name="l00061"></a><span class="lineno">   61</span>&#160;      fprintf(stdout,<span class="stringliteral">&quot;GPUassert: %s %s %d\n&quot;</span>, cudaGetErrorString(code), file, line);</div><div class="line"><a name="l00062"></a><span class="lineno">   62</span>&#160;      <span class="keywordflow">if</span> (abort) exit(code);</div><div class="line"><a name="l00063"></a><span class="lineno">   63</span>&#160;   }</div><div class="line"><a name="l00064"></a><span class="lineno">   64</span>&#160;}</div><div class="line"><a name="l00065"></a><span class="lineno">   65</span>&#160;</div><div class="line"><a name="l00066"></a><span class="lineno">   66</span>&#160;</div><div class="line"><a name="l00067"></a><span class="lineno">   67</span>&#160;std::map&lt;std::string,float*&gt; <a class="code" href="layers_8h.html#a2bb98fbee87212254c977e746e4596e1">init_buffer_map</a>();</div><div class="line"><a name="l00068"></a><span class="lineno">   68</span>&#160;</div><div class="line"><a name="l00073"></a><span class="lineno">   73</span>&#160;__global__ <span class="keywordtype">void</span> <a class="code" href="layers_8h.html#a89f66b9c8c2fec36a8bafc064cca64d0">SoftmaxLossBackprop</a>(<span class="keyword">const</span> <span class="keywordtype">int</span> *label, <span class="keywordtype">int</span> num_labels, <span class="keywordtype">int</span> batch_size, <span class="keywordtype">float</span> *diff);</div><div class="line"><a name="l00074"></a><span class="lineno">   74</span>&#160;</div><div class="line"><a name="l00078"></a><span class="lineno">   78</span>&#160;__global__ <span class="keywordtype">void</span> <a class="code" href="layers_8h.html#ac1954f064bd25ef443e4f3fb9db90d88">matrixMultiplyShared</a>(<span class="keywordtype">float</span> * A, <span class="keywordtype">float</span> * B, <span class="keywordtype">float</span> * C,</div><div class="line"><a name="l00079"></a><span class="lineno">   79</span>&#160;                                    <span class="keywordtype">int</span> numARows, <span class="keywordtype">int</span> numAColumns,</div><div class="line"><a name="l00080"></a><span class="lineno">   80</span>&#160;                                    <span class="keywordtype">int</span> numBRows, <span class="keywordtype">int</span> numBColumns,</div><div class="line"><a name="l00081"></a><span class="lineno">   81</span>&#160;                                    <span class="keywordtype">int</span> numCRows, <span class="keywordtype">int</span> numCColumns);</div><div class="line"><a name="l00082"></a><span class="lineno">   82</span>&#160;</div><div class="line"><a name="l00083"></a><span class="lineno">   83</span>&#160;</div><div class="line"><a name="l00087"></a><span class="lineno">   87</span>&#160;__global__ <span class="keywordtype">void</span> <a class="code" href="layers_8h.html#ac752072214b57ad911f8b833effb67c1">transposeCoalesced</a>(<span class="keywordtype">float</span> *odata, <span class="keyword">const</span> <span class="keywordtype">float</span> *idata,<span class="keywordtype">int</span> idata_rows,<span class="keywordtype">int</span> idata_cols);</div><div class="line"><a name="l00088"></a><span class="lineno">   88</span>&#160;</div><div class="line"><a name="l00092"></a><span class="lineno">   92</span>&#160;__global__ <span class="keywordtype">void</span> <a class="code" href="layers_8h.html#adaec873865a66dd1361e7fdb8cbaceb5">matrixMultiplyNaive</a>(<span class="keywordtype">float</span> * A, <span class="keywordtype">float</span> * B, <span class="keywordtype">float</span> * C,</div><div class="line"><a name="l00093"></a><span class="lineno">   93</span>&#160;                                    <span class="keywordtype">int</span> N,<span class="keywordtype">int</span> K,<span class="keywordtype">int</span> M);</div><div class="line"><a name="l00094"></a><span class="lineno">   94</span>&#160;</div><div class="line"><a name="l00095"></a><span class="lineno">   95</span>&#160;                                    </div><div class="line"><a name="l00099"></a><span class="lineno">   99</span>&#160;__global__ <span class="keywordtype">void</span> <a class="code" href="layers_8h.html#a97afc435921c1d3559b853bfd2eb0f82">transposeNaive</a>(<span class="keywordtype">float</span> *odata, <span class="keyword">const</span> <span class="keywordtype">float</span> *idata,<span class="keywordtype">int</span> idata_rows,<span class="keywordtype">int</span> idata_cols);</div><div class="line"><a name="l00100"></a><span class="lineno">  100</span>&#160;</div><div class="line"><a name="l00108"></a><span class="lineno">  108</span>&#160;__global__ <span class="keywordtype">void</span> <a class="code" href="layers_8h.html#a7b854a420832e9f14150721344c72a3d">update</a>(<span class="keywordtype">float</span> * weights, <span class="keywordtype">float</span> * grad,<span class="keywordtype">float</span> lr,<span class="keywordtype">int</span> N);</div><div class="line"><a name="l00109"></a><span class="lineno">  109</span>&#160;</div><div class="line"><a name="l00110"></a><span class="lineno">  110</span>&#160;<span class="keywordtype">int</span> <a class="code" href="layers_8h.html#a8e8e4496b1eab58d59081f2d823a481c">calc_bytes_from_shape</a>(<span class="keywordtype">int</span> shape[]);</div><div class="line"><a name="l00111"></a><span class="lineno">  111</span>&#160;</div><div class="line"><a name="l00118"></a><span class="lineno">  118</span>&#160;<span class="keyword">namespace </span><a class="code" href="namespacelayers.html">layers</a></div><div class="line"><a name="l00119"></a><span class="lineno">  119</span>&#160;{</div><div class="line"><a name="l00125"></a><span class="lineno"><a class="line" href="classlayers_1_1_layer.html">  125</a></span>&#160;  <span class="keyword">class </span><a class="code" href="classlayers_1_1_layer.html">Layer</a></div><div class="line"><a name="l00126"></a><span class="lineno">  126</span>&#160;  {</div><div class="line"><a name="l00127"></a><span class="lineno">  127</span>&#160;    <span class="keyword">public</span>:</div><div class="line"><a name="l00128"></a><span class="lineno"><a class="line" href="classlayers_1_1_layer.html#a918cc34c6ee46f2a59f5fb1a78144d47">  128</a></span>&#160;      <span class="keywordtype">int</span> <a class="code" href="classlayers_1_1_layer.html#a918cc34c6ee46f2a59f5fb1a78144d47">obatch_size</a>; </div><div class="line"><a name="l00129"></a><span class="lineno"><a class="line" href="classlayers_1_1_layer.html#aa2efe4c17dccde169457bb4f4c1c6c36">  129</a></span>&#160;      <span class="keywordtype">int</span> <a class="code" href="classlayers_1_1_layer.html#aa2efe4c17dccde169457bb4f4c1c6c36">ochannels</a>; </div><div class="line"><a name="l00130"></a><span class="lineno"><a class="line" href="classlayers_1_1_layer.html#acffdaf5a36df735f7f4cc1d432dabaaf">  130</a></span>&#160;      <span class="keywordtype">int</span> <a class="code" href="classlayers_1_1_layer.html#acffdaf5a36df735f7f4cc1d432dabaaf">oheight</a>; </div><div class="line"><a name="l00131"></a><span class="lineno"><a class="line" href="classlayers_1_1_layer.html#a72cbb8c4ac7c0238d43b93e24f4bfd1b">  131</a></span>&#160;      <span class="keywordtype">int</span> <a class="code" href="classlayers_1_1_layer.html#a72cbb8c4ac7c0238d43b93e24f4bfd1b">owidth</a>; </div><div class="line"><a name="l00132"></a><span class="lineno"><a class="line" href="classlayers_1_1_layer.html#acccaf0a0e2b51be5f906cd35a9dfecfd">  132</a></span>&#160;      <span class="keywordtype">int</span> <a class="code" href="classlayers_1_1_layer.html#acccaf0a0e2b51be5f906cd35a9dfecfd">ibatch_size</a>; </div><div class="line"><a name="l00133"></a><span class="lineno"><a class="line" href="classlayers_1_1_layer.html#a7a8cbc3a34cf5f159128126c67ed5ab9">  133</a></span>&#160;      <span class="keywordtype">int</span> <a class="code" href="classlayers_1_1_layer.html#a7a8cbc3a34cf5f159128126c67ed5ab9">ichannels</a>; </div><div class="line"><a name="l00134"></a><span class="lineno"><a class="line" href="classlayers_1_1_layer.html#aed99be2a4243da8e825988407860ce10">  134</a></span>&#160;      <span class="keywordtype">int</span> <a class="code" href="classlayers_1_1_layer.html#aed99be2a4243da8e825988407860ce10">iheight</a>; </div><div class="line"><a name="l00135"></a><span class="lineno"><a class="line" href="classlayers_1_1_layer.html#a1845ee31120e3e23b1a382f553476455">  135</a></span>&#160;      <span class="keywordtype">int</span> <a class="code" href="classlayers_1_1_layer.html#a1845ee31120e3e23b1a382f553476455">iwidth</a>; </div><div class="line"><a name="l00136"></a><span class="lineno">  136</span>&#160;      <span class="keywordtype">void</span> <a class="code" href="classlayers_1_1_layer.html#a43323bc39883290a4788f6f8f9961949">forward</a>(); </div><div class="line"><a name="l00137"></a><span class="lineno">  137</span>&#160;      <span class="keyword">virtual</span> <span class="keywordtype">int</span> <a class="code" href="classlayers_1_1_layer.html#aab131a3792c61ee36d5d650df27eb650">get_total_memory</a>()=0; </div><div class="line"><a name="l00139"></a><span class="lineno">  139</span>&#160;  };</div><div class="line"><a name="l00140"></a><span class="lineno">  140</span>&#160;</div><div class="line"><a name="l00141"></a><span class="lineno">  141</span>&#160;}</div><div class="line"><a name="l00142"></a><span class="lineno">  142</span>&#160;</div><div class="line"><a name="l00148"></a><span class="lineno">  148</span>&#160;<span class="keyword">namespace </span><a class="code" href="namespacenetwork.html">network</a></div><div class="line"><a name="l00149"></a><span class="lineno">  149</span>&#160;{</div><div class="line"><a name="l00155"></a><span class="lineno"><a class="line" href="classnetwork_1_1seq_network.html">  155</a></span>&#160;  <span class="keyword">class </span><a class="code" href="classnetwork_1_1seq_network.html">seqNetwork</a></div><div class="line"><a name="l00156"></a><span class="lineno">  156</span>&#160;  {</div><div class="line"><a name="l00157"></a><span class="lineno">  157</span>&#160;    <span class="keyword">public</span>:</div><div class="line"><a name="l00158"></a><span class="lineno"><a class="line" href="classnetwork_1_1seq_network.html#a74c4bed65724ccec7d94d69e0f324f36">  158</a></span>&#160;      <span class="keywordtype">int</span> <a class="code" href="classnetwork_1_1seq_network.html#a74c4bed65724ccec7d94d69e0f324f36">num_layers</a>; </div><div class="line"><a name="l00159"></a><span class="lineno"><a class="line" href="classnetwork_1_1seq_network.html#a2823a8d660305acb891dedc2a3c71285">  159</a></span>&#160;      <span class="keywordtype">float</span> <a class="code" href="classnetwork_1_1seq_network.html#a2823a8d660305acb891dedc2a3c71285">lr</a>; </div><div class="line"><a name="l00160"></a><span class="lineno"><a class="line" href="classnetwork_1_1seq_network.html#a545ec28e39b0750957ec7567ba628191">  160</a></span>&#160;      <span class="keywordtype">int</span> <a class="code" href="classnetwork_1_1seq_network.html#a545ec28e39b0750957ec7567ba628191">batch_size</a>; </div><div class="line"><a name="l00161"></a><span class="lineno"><a class="line" href="classnetwork_1_1seq_network.html#ac8aadabba842e81b7a94ec66488c7736">  161</a></span>&#160;      std::vector&lt;std::vector&lt;std::string &gt; &gt; <a class="code" href="classnetwork_1_1seq_network.html#ac8aadabba842e81b7a94ec66488c7736">layer_info</a>; </div><div class="line"><a name="l00162"></a><span class="lineno"><a class="line" href="classnetwork_1_1seq_network.html#a4ff0d13327a05bc3d5cca84848c856fb">  162</a></span>&#160;      std::vector&lt;std::map&lt;std::string,float*&gt; &gt; <a class="code" href="classnetwork_1_1seq_network.html#a4ff0d13327a05bc3d5cca84848c856fb">layer_buffers</a>; </div><div class="line"><a name="l00163"></a><span class="lineno"><a class="line" href="classnetwork_1_1seq_network.html#af2eaef98d51f230a07f695f3b57f6c63">  163</a></span>&#160;      std::vector&lt;std::map&lt;std::string,float*&gt; &gt; <a class="code" href="classnetwork_1_1seq_network.html#af2eaef98d51f230a07f695f3b57f6c63">layer_offloaded_buffers</a>; </div><div class="line"><a name="l00164"></a><span class="lineno"><a class="line" href="classnetwork_1_1seq_network.html#ad44dd0adfaee158f52249851c8a4f314">  164</a></span>&#160;      std::vector&lt;std::map&lt;std::string,int&gt; &gt; <a class="code" href="classnetwork_1_1seq_network.html#ad44dd0adfaee158f52249851c8a4f314">layer_buffer_bytes</a>; </div><div class="line"><a name="l00165"></a><span class="lineno"><a class="line" href="classnetwork_1_1seq_network.html#a93d1c216952051ce8909b13e35a1fe6b">  165</a></span>&#160;      std::vector&lt;std::map&lt;std::string,int&gt; &gt; <a class="code" href="classnetwork_1_1seq_network.html#a93d1c216952051ce8909b13e35a1fe6b">layer_buffer_redundant_bytes</a>; </div><div class="line"><a name="l00166"></a><span class="lineno"><a class="line" href="classnetwork_1_1seq_network.html#af28267557a78acf0992301ff3797b4d8">  166</a></span>&#160;      std::vector&lt; layers::Layer *&gt; <a class="code" href="classnetwork_1_1seq_network.html#af28267557a78acf0992301ff3797b4d8">layer_objects</a>; </div><div class="line"><a name="l00169"></a><span class="lineno"><a class="line" href="classnetwork_1_1seq_network.html#a596b38b7778ce099ef37a821bee93d93">  169</a></span>&#160;      cudnnHandle_t <a class="code" href="classnetwork_1_1seq_network.html#a596b38b7778ce099ef37a821bee93d93">handle</a>; </div><div class="line"><a name="l00170"></a><span class="lineno"><a class="line" href="classnetwork_1_1seq_network.html#a3de3372e498824eec49453999adda7ad">  170</a></span>&#160;      cublasHandle_t <a class="code" href="classnetwork_1_1seq_network.html#a3de3372e498824eec49453999adda7ad">blas_handle</a>; </div><div class="line"><a name="l00181"></a><span class="lineno">  181</span>&#160;      <a class="code" href="classnetwork_1_1seq_network.html">seqNetwork</a>(cudnnHandle_t cudnn,cublasHandle_t cublas,std::vector&lt;std::string&gt; &amp;specs, <span class="keywordtype">float</span> lr, <span class="keywordtype">unsigned</span> max_allowed_bytes,<span class="keywordtype">int</span> sub_batch_selection);</div><div class="line"><a name="l00182"></a><span class="lineno">  182</span>&#160;      </div><div class="line"><a name="l00186"></a><span class="lineno">  186</span>&#160;      <span class="keywordtype">void</span> print_network_info();</div><div class="line"><a name="l00187"></a><span class="lineno">  187</span>&#160;</div><div class="line"><a name="l00193"></a><span class="lineno">  193</span>&#160;      <span class="keywordtype">void</span> get_output_shape(<span class="keywordtype">int</span> shape[], <span class="keywordtype">int</span> i);</div><div class="line"><a name="l00194"></a><span class="lineno">  194</span>&#160;</div><div class="line"><a name="l00195"></a><span class="lineno">  195</span>&#160;      </div><div class="line"><a name="l00199"></a><span class="lineno">  199</span>&#160;      <span class="keywordtype">void</span> randomise_batch(); <span class="comment">//randomise input to the neural network</span></div><div class="line"><a name="l00200"></a><span class="lineno">  200</span>&#160;      </div><div class="line"><a name="l00206"></a><span class="lineno">  206</span>&#160;      <span class="keywordtype">void</span> update_batch(<span class="keywordtype">float</span>* data, <span class="keywordtype">int</span>* labels);</div><div class="line"><a name="l00207"></a><span class="lineno">  207</span>&#160;</div><div class="line"><a name="l00208"></a><span class="lineno">  208</span>&#160;      <span class="comment">// void enqueue_batch(float * batch);</span></div><div class="line"><a name="l00209"></a><span class="lineno">  209</span>&#160;</div><div class="line"><a name="l00215"></a><span class="lineno">  215</span>&#160;      <span class="keywordtype">void</span> enqueue_batch_loop(<span class="keywordtype">int</span> loop_no);</div><div class="line"><a name="l00216"></a><span class="lineno">  216</span>&#160;</div><div class="line"><a name="l00220"></a><span class="lineno">  220</span>&#160;      <span class="keywordtype">void</span> randomise_params();</div><div class="line"><a name="l00221"></a><span class="lineno">  221</span>&#160;</div><div class="line"><a name="l00226"></a><span class="lineno">  226</span>&#160;      <span class="keywordtype">void</span> <a class="code" href="classlayers_1_1_layer.html#a43323bc39883290a4788f6f8f9961949">forward</a>();</div><div class="line"><a name="l00227"></a><span class="lineno">  227</span>&#160;</div><div class="line"><a name="l00232"></a><span class="lineno">  232</span>&#160;      <span class="keywordtype">void</span> forward_layer(<span class="keywordtype">int</span> layer_number);</div><div class="line"><a name="l00233"></a><span class="lineno">  233</span>&#160;</div><div class="line"><a name="l00238"></a><span class="lineno">  238</span>&#160;      <span class="keywordtype">void</span> backward();</div><div class="line"><a name="l00239"></a><span class="lineno">  239</span>&#160;</div><div class="line"><a name="l00244"></a><span class="lineno">  244</span>&#160;      <span class="keywordtype">void</span> backward_layer(<span class="keywordtype">int</span> layer_number,<span class="keywordtype">float</span> beta);</div><div class="line"><a name="l00245"></a><span class="lineno">  245</span>&#160;</div><div class="line"><a name="l00249"></a><span class="lineno">  249</span>&#160;      <span class="keywordtype">void</span> train();</div><div class="line"><a name="l00250"></a><span class="lineno">  250</span>&#160;</div><div class="line"><a name="l00255"></a><span class="lineno">  255</span>&#160;      <span class="keywordtype">void</span> update_weights();</div><div class="line"><a name="l00256"></a><span class="lineno">  256</span>&#160;</div><div class="line"><a name="l00261"></a><span class="lineno">  261</span>&#160;      <span class="keywordtype">int</span> <a class="code" href="classlayers_1_1_layer.html#aab131a3792c61ee36d5d650df27eb650">get_total_memory</a>();</div><div class="line"><a name="l00262"></a><span class="lineno">  262</span>&#160;</div><div class="line"><a name="l00266"></a><span class="lineno">  266</span>&#160;      <span class="keywordtype">unsigned</span> get_max_memory();</div><div class="line"><a name="l00267"></a><span class="lineno">  267</span>&#160;</div><div class="line"><a name="l00271"></a><span class="lineno">  271</span>&#160;      <span class="keywordtype">void</span> allocate_all_memory(<a class="code" href="classvmm.html">vmm</a> * mem_manager);</div><div class="line"><a name="l00272"></a><span class="lineno">  272</span>&#160;</div><div class="line"><a name="l00276"></a><span class="lineno">  276</span>&#160;      <span class="keywordtype">unsigned</span> getMemoryLowerBound();</div><div class="line"><a name="l00277"></a><span class="lineno">  277</span>&#160;</div><div class="line"><a name="l00281"></a><span class="lineno">  281</span>&#160;      <span class="keywordtype">unsigned</span> sub_batch_size();</div><div class="line"><a name="l00282"></a><span class="lineno">  282</span>&#160;</div><div class="line"><a name="l00286"></a><span class="lineno">  286</span>&#160;      <span class="keywordtype">void</span> link_layer_buffer_fw(<span class="keywordtype">int</span> layer_number);</div><div class="line"><a name="l00287"></a><span class="lineno">  287</span>&#160;      </div><div class="line"><a name="l00291"></a><span class="lineno">  291</span>&#160;      <span class="keywordtype">void</span> link_layer_buffer_bw(<span class="keywordtype">int</span> layer_number);</div><div class="line"><a name="l00292"></a><span class="lineno">  292</span>&#160;</div><div class="line"><a name="l00296"></a><span class="lineno">  296</span>&#160;      <span class="keywordtype">int</span> get_loops();</div><div class="line"><a name="l00297"></a><span class="lineno">  297</span>&#160;</div><div class="line"><a name="l00302"></a><span class="lineno">  302</span>&#160;      <span class="keywordtype">int</span> get_max_batch_size();</div><div class="line"><a name="l00303"></a><span class="lineno">  303</span>&#160;</div><div class="line"><a name="l00311"></a><span class="lineno">  311</span>&#160;      <span class="keywordtype">float</span>* offload_buffer(<span class="keywordtype">int</span> layer_number,std::string type,<span class="keywordtype">int</span> shape[],<span class="keywordtype">int</span> async=1); </div><div class="line"><a name="l00312"></a><span class="lineno">  312</span>&#160;</div><div class="line"><a name="l00319"></a><span class="lineno">  319</span>&#160;      <span class="keywordtype">float</span>* prefetch_buffer(<span class="keywordtype">int</span> layer_number, std::string type,<span class="keywordtype">int</span> shape[]);</div><div class="line"><a name="l00320"></a><span class="lineno">  320</span>&#160;</div><div class="line"><a name="l00326"></a><span class="lineno">  326</span>&#160;      <span class="keywordtype">void</span> allocate_mem_layer_fw(<span class="keywordtype">int</span> layer_number, <a class="code" href="classvmm.html">vmm</a> * mem_manager);</div><div class="line"><a name="l00327"></a><span class="lineno">  327</span>&#160;      </div><div class="line"><a name="l00333"></a><span class="lineno">  333</span>&#160;      <span class="keywordtype">void</span> allocate_mem_layer_bw(<span class="keywordtype">int</span> layer_number, <a class="code" href="classvmm.html">vmm</a> * mem_manager);</div><div class="line"><a name="l00334"></a><span class="lineno">  334</span>&#160;   </div><div class="line"><a name="l00340"></a><span class="lineno">  340</span>&#160;      <span class="keywordtype">void</span> allocate_mem_layer_bw_h1(<span class="keywordtype">int</span> layer_number, <a class="code" href="classvmm.html">vmm</a> * mem_manager);</div><div class="line"><a name="l00341"></a><span class="lineno">  341</span>&#160;</div><div class="line"><a name="l00347"></a><span class="lineno">  347</span>&#160;      <span class="keywordtype">void</span> deallocate_mem_layer_fw(<span class="keywordtype">int</span> layer_number, <a class="code" href="classvmm.html">vmm</a> * mem_manager,<span class="keywordtype">int</span> local=0);</div><div class="line"><a name="l00348"></a><span class="lineno">  348</span>&#160;</div><div class="line"><a name="l00354"></a><span class="lineno">  354</span>&#160;      <span class="keywordtype">void</span> deallocate_mem_layer_bw(<span class="keywordtype">int</span> layer_number, <a class="code" href="classvmm.html">vmm</a> * mem_manager,<span class="keywordtype">int</span> local=0);</div><div class="line"><a name="l00355"></a><span class="lineno">  355</span>&#160;</div><div class="line"><a name="l00360"></a><span class="lineno">  360</span>&#160;      <span class="keywordtype">void</span> allocate_mem_params(<a class="code" href="classvmm.html">vmm</a> * mem_manager);</div><div class="line"><a name="l00361"></a><span class="lineno">  361</span>&#160;</div><div class="line"><a name="l00365"></a><span class="lineno">  365</span>&#160;      ~<a class="code" href="classnetwork_1_1seq_network.html">seqNetwork</a>();</div><div class="line"><a name="l00366"></a><span class="lineno">  366</span>&#160;</div><div class="line"><a name="l00367"></a><span class="lineno">  367</span>&#160;    <span class="keyword">private</span>:</div><div class="line"><a name="l00371"></a><span class="lineno">  371</span>&#160;      <span class="keywordtype">void</span> forward_();</div><div class="line"><a name="l00372"></a><span class="lineno">  372</span>&#160;</div><div class="line"><a name="l00377"></a><span class="lineno">  377</span>&#160;      <span class="keywordtype">void</span> backward_(<span class="keywordtype">float</span> beta);</div><div class="line"><a name="l00378"></a><span class="lineno">  378</span>&#160;</div><div class="line"><a name="l00382"></a><span class="lineno">  382</span>&#160;      <span class="keywordtype">void</span> make_nn_objs(<span class="keywordtype">unsigned</span> sub_batch_size);</div><div class="line"><a name="l00383"></a><span class="lineno">  383</span>&#160;      <span class="keywordtype">void</span> link_all_buffers();</div><div class="line"><a name="l00384"></a><span class="lineno">  384</span>&#160;</div><div class="line"><a name="l00388"></a><span class="lineno">  388</span>&#160;      <span class="keywordtype">unsigned</span> calculate_sub_batch();</div><div class="line"><a name="l00389"></a><span class="lineno">  389</span>&#160;</div><div class="line"><a name="l00394"></a><span class="lineno">  394</span>&#160;      <span class="keywordtype">int</span> get_total_memory_();</div><div class="line"><a name="l00395"></a><span class="lineno">  395</span>&#160;</div><div class="line"><a name="l00399"></a><span class="lineno">  399</span>&#160;      <span class="keywordtype">unsigned</span> getMemoryLowerBound_();</div><div class="line"><a name="l00400"></a><span class="lineno">  400</span>&#160;</div><div class="line"><a name="l00405"></a><span class="lineno">  405</span>&#160;      <span class="keywordtype">bool</span> profile_subbatch_validity(<span class="keywordtype">unsigned</span> batch_size);</div><div class="line"><a name="l00406"></a><span class="lineno">  406</span>&#160;</div><div class="line"><a name="l00407"></a><span class="lineno"><a class="line" href="classnetwork_1_1seq_network.html#a659234506728acfc3e30858479628400">  407</a></span>&#160;      <span class="keywordtype">unsigned</span> <a class="code" href="classnetwork_1_1seq_network.html#a659234506728acfc3e30858479628400">max_sub_batch_size_</a>; </div><div class="line"><a name="l00408"></a><span class="lineno"><a class="line" href="classnetwork_1_1seq_network.html#a4b49501958dabb586506c8be7dd4291b">  408</a></span>&#160;      cudaStream_t <a class="code" href="classnetwork_1_1seq_network.html#a4b49501958dabb586506c8be7dd4291b">memory_stream_</a>; </div><div class="line"><a name="l00409"></a><span class="lineno"><a class="line" href="classnetwork_1_1seq_network.html#a1c376b3bb31bba27bf259737148185f9">  409</a></span>&#160;      cudaStream_t <a class="code" href="classnetwork_1_1seq_network.html#a1c376b3bb31bba27bf259737148185f9">compute_stream_</a>; </div><div class="line"><a name="l00410"></a><span class="lineno"><a class="line" href="classnetwork_1_1seq_network.html#ae0fa02cae04d719b6c04c0a309c302d1">  410</a></span>&#160;      <span class="keywordtype">unsigned</span> <a class="code" href="classnetwork_1_1seq_network.html#ae0fa02cae04d719b6c04c0a309c302d1">sub_batch_size_</a>; </div><div class="line"><a name="l00411"></a><span class="lineno"><a class="line" href="classnetwork_1_1seq_network.html#a73e9d7f135cd4f1a27b4ed52ffa56bf0">  411</a></span>&#160;      <span class="keywordtype">unsigned</span> <a class="code" href="classnetwork_1_1seq_network.html#a73e9d7f135cd4f1a27b4ed52ffa56bf0">max_allowed_bytes_</a>; </div><div class="line"><a name="l00412"></a><span class="lineno"><a class="line" href="classnetwork_1_1seq_network.html#af69649bf2346ac1fd676c87d8b8c7146">  412</a></span>&#160;      <span class="keywordtype">unsigned</span> <a class="code" href="classnetwork_1_1seq_network.html#af69649bf2346ac1fd676c87d8b8c7146">weights_memory_bytes_</a>; </div><div class="line"><a name="l00413"></a><span class="lineno"><a class="line" href="classnetwork_1_1seq_network.html#a1204f57234cd9b67b1dfcf941a440535">  413</a></span>&#160;      <span class="keywordtype">unsigned</span> <a class="code" href="classnetwork_1_1seq_network.html#a1204f57234cd9b67b1dfcf941a440535">total_seqnet_bytes_</a>; </div><div class="line"><a name="l00414"></a><span class="lineno"><a class="line" href="classnetwork_1_1seq_network.html#a714fdbbccad219582ee8bc2b797b066b">  414</a></span>&#160;      <span class="keywordtype">unsigned</span> <a class="code" href="classnetwork_1_1seq_network.html#a714fdbbccad219582ee8bc2b797b066b">min_seqnet_bytes_</a>; </div><div class="line"><a name="l00415"></a><span class="lineno"><a class="line" href="classnetwork_1_1seq_network.html#acfcd17bf4969cb34706a26ddd212c2a8">  415</a></span>&#160;      <span class="keywordtype">unsigned</span> <a class="code" href="classnetwork_1_1seq_network.html#acfcd17bf4969cb34706a26ddd212c2a8">max_seqnet_memory_</a>; </div><div class="line"><a name="l00416"></a><span class="lineno"><a class="line" href="classnetwork_1_1seq_network.html#a268fdc8d957391bcf58d87420c5b408c">  416</a></span>&#160;      <span class="keywordtype">float</span>* <a class="code" href="classnetwork_1_1seq_network.html#a268fdc8d957391bcf58d87420c5b408c">batch_data_</a>; </div><div class="line"><a name="l00417"></a><span class="lineno"><a class="line" href="classnetwork_1_1seq_network.html#a2abaa80163ffc186247d3bb9fed64edc">  417</a></span>&#160;      <span class="keywordtype">int</span>* <a class="code" href="classnetwork_1_1seq_network.html#a2abaa80163ffc186247d3bb9fed64edc">batch_labels_</a>; </div><div class="line"><a name="l00418"></a><span class="lineno"><a class="line" href="classnetwork_1_1seq_network.html#a4089a7cefb6d92210ed971a73c917990">  418</a></span>&#160;      <span class="keywordtype">int</span> <a class="code" href="classnetwork_1_1seq_network.html#a4089a7cefb6d92210ed971a73c917990">sync_layer_no_</a>; </div><div class="line"><a name="l00419"></a><span class="lineno"><a class="line" href="classnetwork_1_1seq_network.html#a986bf55a752b11cb0b1dcffb137fd51f">  419</a></span>&#160;      <span class="keywordtype">int</span> <a class="code" href="classnetwork_1_1seq_network.html#a986bf55a752b11cb0b1dcffb137fd51f">prefetch_trigger_layer_no_</a>; </div><div class="line"><a name="l00420"></a><span class="lineno"><a class="line" href="classnetwork_1_1seq_network.html#a122ddaf94dd7b41f7114a99f513c3a01">  420</a></span>&#160;      <span class="keywordtype">int</span> <a class="code" href="classnetwork_1_1seq_network.html#a122ddaf94dd7b41f7114a99f513c3a01">last_prefetched_layer_no_</a>; </div><div class="line"><a name="l00421"></a><span class="lineno">  421</span>&#160;  };</div><div class="line"><a name="l00422"></a><span class="lineno">  422</span>&#160;}</div><div class="line"><a name="l00423"></a><span class="lineno">  423</span>&#160;</div><div class="line"><a name="l00424"></a><span class="lineno">  424</span>&#160;<span class="preprocessor">#endif</span></div><div class="ttc" id="namespacenetwork_html"><div class="ttname"><a href="namespacenetwork.html">network</a></div><div class="ttdoc">Contains all function and classes involving initialization training of neural networks. </div></div>
<div class="ttc" id="classlayers_1_1_layer_html_a1845ee31120e3e23b1a382f553476455"><div class="ttname"><a href="classlayers_1_1_layer.html#a1845ee31120e3e23b1a382f553476455">layers::Layer::iwidth</a></div><div class="ttdeci">int iwidth</div><div class="ttdef"><b>Definition:</b> <a href="layers_8h_source.html#l00135">layers.h:135</a></div></div>
<div class="ttc" id="classlayers_1_1_layer_html_acffdaf5a36df735f7f4cc1d432dabaaf"><div class="ttname"><a href="classlayers_1_1_layer.html#acffdaf5a36df735f7f4cc1d432dabaaf">layers::Layer::oheight</a></div><div class="ttdeci">int oheight</div><div class="ttdef"><b>Definition:</b> <a href="layers_8h_source.html#l00130">layers.h:130</a></div></div>
<div class="ttc" id="classnetwork_1_1seq_network_html_a268fdc8d957391bcf58d87420c5b408c"><div class="ttname"><a href="classnetwork_1_1seq_network.html#a268fdc8d957391bcf58d87420c5b408c">network::seqNetwork::batch_data_</a></div><div class="ttdeci">float * batch_data_</div><div class="ttdef"><b>Definition:</b> <a href="layers_8h_source.html#l00416">layers.h:416</a></div></div>
<div class="ttc" id="classlayers_1_1_layer_html_aab131a3792c61ee36d5d650df27eb650"><div class="ttname"><a href="classlayers_1_1_layer.html#aab131a3792c61ee36d5d650df27eb650">layers::Layer::get_total_memory</a></div><div class="ttdeci">virtual int get_total_memory()=0</div></div>
<div class="ttc" id="classlayers_1_1_layer_html_aa2efe4c17dccde169457bb4f4c1c6c36"><div class="ttname"><a href="classlayers_1_1_layer.html#aa2efe4c17dccde169457bb4f4c1c6c36">layers::Layer::ochannels</a></div><div class="ttdeci">int ochannels</div><div class="ttdef"><b>Definition:</b> <a href="layers_8h_source.html#l00129">layers.h:129</a></div></div>
<div class="ttc" id="classnetwork_1_1seq_network_html_a545ec28e39b0750957ec7567ba628191"><div class="ttname"><a href="classnetwork_1_1seq_network.html#a545ec28e39b0750957ec7567ba628191">network::seqNetwork::batch_size</a></div><div class="ttdeci">int batch_size</div><div class="ttdef"><b>Definition:</b> <a href="layers_8h_source.html#l00160">layers.h:160</a></div></div>
<div class="ttc" id="classnetwork_1_1seq_network_html_a714fdbbccad219582ee8bc2b797b066b"><div class="ttname"><a href="classnetwork_1_1seq_network.html#a714fdbbccad219582ee8bc2b797b066b">network::seqNetwork::min_seqnet_bytes_</a></div><div class="ttdeci">unsigned min_seqnet_bytes_</div><div class="ttdef"><b>Definition:</b> <a href="layers_8h_source.html#l00414">layers.h:414</a></div></div>
<div class="ttc" id="classnetwork_1_1seq_network_html"><div class="ttname"><a href="classnetwork_1_1seq_network.html">network::seqNetwork</a></div><div class="ttdoc">Main neural network class. </div><div class="ttdef"><b>Definition:</b> <a href="layers_8h_source.html#l00155">layers.h:155</a></div></div>
<div class="ttc" id="classnetwork_1_1seq_network_html_a596b38b7778ce099ef37a821bee93d93"><div class="ttname"><a href="classnetwork_1_1seq_network.html#a596b38b7778ce099ef37a821bee93d93">network::seqNetwork::handle</a></div><div class="ttdeci">cudnnHandle_t handle</div><div class="ttdef"><b>Definition:</b> <a href="layers_8h_source.html#l00169">layers.h:169</a></div></div>
<div class="ttc" id="classnetwork_1_1seq_network_html_af69649bf2346ac1fd676c87d8b8c7146"><div class="ttname"><a href="classnetwork_1_1seq_network.html#af69649bf2346ac1fd676c87d8b8c7146">network::seqNetwork::weights_memory_bytes_</a></div><div class="ttdeci">unsigned weights_memory_bytes_</div><div class="ttdef"><b>Definition:</b> <a href="layers_8h_source.html#l00412">layers.h:412</a></div></div>
<div class="ttc" id="classnetwork_1_1seq_network_html_a4b49501958dabb586506c8be7dd4291b"><div class="ttname"><a href="classnetwork_1_1seq_network.html#a4b49501958dabb586506c8be7dd4291b">network::seqNetwork::memory_stream_</a></div><div class="ttdeci">cudaStream_t memory_stream_</div><div class="ttdef"><b>Definition:</b> <a href="layers_8h_source.html#l00408">layers.h:408</a></div></div>
<div class="ttc" id="classnetwork_1_1seq_network_html_a122ddaf94dd7b41f7114a99f513c3a01"><div class="ttname"><a href="classnetwork_1_1seq_network.html#a122ddaf94dd7b41f7114a99f513c3a01">network::seqNetwork::last_prefetched_layer_no_</a></div><div class="ttdeci">int last_prefetched_layer_no_</div><div class="ttdef"><b>Definition:</b> <a href="layers_8h_source.html#l00420">layers.h:420</a></div></div>
<div class="ttc" id="classlayers_1_1_layer_html_a43323bc39883290a4788f6f8f9961949"><div class="ttname"><a href="classlayers_1_1_layer.html#a43323bc39883290a4788f6f8f9961949">layers::Layer::forward</a></div><div class="ttdeci">void forward()</div></div>
<div class="ttc" id="classnetwork_1_1seq_network_html_af2eaef98d51f230a07f695f3b57f6c63"><div class="ttname"><a href="classnetwork_1_1seq_network.html#af2eaef98d51f230a07f695f3b57f6c63">network::seqNetwork::layer_offloaded_buffers</a></div><div class="ttdeci">std::vector&lt; std::map&lt; std::string, float * &gt; &gt; layer_offloaded_buffers</div><div class="ttdef"><b>Definition:</b> <a href="layers_8h_source.html#l00163">layers.h:163</a></div></div>
<div class="ttc" id="classnetwork_1_1seq_network_html_af28267557a78acf0992301ff3797b4d8"><div class="ttname"><a href="classnetwork_1_1seq_network.html#af28267557a78acf0992301ff3797b4d8">network::seqNetwork::layer_objects</a></div><div class="ttdeci">std::vector&lt; layers::Layer * &gt; layer_objects</div><div class="ttdef"><b>Definition:</b> <a href="layers_8h_source.html#l00166">layers.h:166</a></div></div>
<div class="ttc" id="layers_8h_html_adaec873865a66dd1361e7fdb8cbaceb5"><div class="ttname"><a href="layers_8h.html#adaec873865a66dd1361e7fdb8cbaceb5">matrixMultiplyNaive</a></div><div class="ttdeci">__global__ void matrixMultiplyNaive(float *A, float *B, float *C, int N, int K, int M)</div></div>
<div class="ttc" id="classnetwork_1_1seq_network_html_a73e9d7f135cd4f1a27b4ed52ffa56bf0"><div class="ttname"><a href="classnetwork_1_1seq_network.html#a73e9d7f135cd4f1a27b4ed52ffa56bf0">network::seqNetwork::max_allowed_bytes_</a></div><div class="ttdeci">unsigned max_allowed_bytes_</div><div class="ttdef"><b>Definition:</b> <a href="layers_8h_source.html#l00411">layers.h:411</a></div></div>
<div class="ttc" id="classnetwork_1_1seq_network_html_a4ff0d13327a05bc3d5cca84848c856fb"><div class="ttname"><a href="classnetwork_1_1seq_network.html#a4ff0d13327a05bc3d5cca84848c856fb">network::seqNetwork::layer_buffers</a></div><div class="ttdeci">std::vector&lt; std::map&lt; std::string, float * &gt; &gt; layer_buffers</div><div class="ttdef"><b>Definition:</b> <a href="layers_8h_source.html#l00162">layers.h:162</a></div></div>
<div class="ttc" id="classlayers_1_1_layer_html_a7a8cbc3a34cf5f159128126c67ed5ab9"><div class="ttname"><a href="classlayers_1_1_layer.html#a7a8cbc3a34cf5f159128126c67ed5ab9">layers::Layer::ichannels</a></div><div class="ttdeci">int ichannels</div><div class="ttdef"><b>Definition:</b> <a href="layers_8h_source.html#l00133">layers.h:133</a></div></div>
<div class="ttc" id="namespacelayers_html"><div class="ttname"><a href="namespacelayers.html">layers</a></div><div class="ttdoc">Contains all function and classes involving neural network layers. </div><div class="ttdef"><b>Definition:</b> <a href="conv__layer_8h_source.html#l00006">conv_layer.h:6</a></div></div>
<div class="ttc" id="classnetwork_1_1seq_network_html_ae0fa02cae04d719b6c04c0a309c302d1"><div class="ttname"><a href="classnetwork_1_1seq_network.html#ae0fa02cae04d719b6c04c0a309c302d1">network::seqNetwork::sub_batch_size_</a></div><div class="ttdeci">unsigned sub_batch_size_</div><div class="ttdef"><b>Definition:</b> <a href="layers_8h_source.html#l00410">layers.h:410</a></div></div>
<div class="ttc" id="classvmm_html"><div class="ttname"><a href="classvmm.html">vmm</a></div><div class="ttdef"><b>Definition:</b> <a href="vmm_8h_source.html#l00060">vmm.h:60</a></div></div>
<div class="ttc" id="layers_8h_html_a8e8e4496b1eab58d59081f2d823a481c"><div class="ttname"><a href="layers_8h.html#a8e8e4496b1eab58d59081f2d823a481c">calc_bytes_from_shape</a></div><div class="ttdeci">int calc_bytes_from_shape(int shape[])</div></div>
<div class="ttc" id="classnetwork_1_1seq_network_html_a1204f57234cd9b67b1dfcf941a440535"><div class="ttname"><a href="classnetwork_1_1seq_network.html#a1204f57234cd9b67b1dfcf941a440535">network::seqNetwork::total_seqnet_bytes_</a></div><div class="ttdeci">unsigned total_seqnet_bytes_</div><div class="ttdef"><b>Definition:</b> <a href="layers_8h_source.html#l00413">layers.h:413</a></div></div>
<div class="ttc" id="classnetwork_1_1seq_network_html_a93d1c216952051ce8909b13e35a1fe6b"><div class="ttname"><a href="classnetwork_1_1seq_network.html#a93d1c216952051ce8909b13e35a1fe6b">network::seqNetwork::layer_buffer_redundant_bytes</a></div><div class="ttdeci">std::vector&lt; std::map&lt; std::string, int &gt; &gt; layer_buffer_redundant_bytes</div><div class="ttdef"><b>Definition:</b> <a href="layers_8h_source.html#l00165">layers.h:165</a></div></div>
<div class="ttc" id="classlayers_1_1_layer_html"><div class="ttname"><a href="classlayers_1_1_layer.html">layers::Layer</a></div><div class="ttdoc">Abstract class Layer. </div><div class="ttdef"><b>Definition:</b> <a href="layers_8h_source.html#l00125">layers.h:125</a></div></div>
<div class="ttc" id="classlayers_1_1_layer_html_acccaf0a0e2b51be5f906cd35a9dfecfd"><div class="ttname"><a href="classlayers_1_1_layer.html#acccaf0a0e2b51be5f906cd35a9dfecfd">layers::Layer::ibatch_size</a></div><div class="ttdeci">int ibatch_size</div><div class="ttdef"><b>Definition:</b> <a href="layers_8h_source.html#l00132">layers.h:132</a></div></div>
<div class="ttc" id="classlayers_1_1_layer_html_a918cc34c6ee46f2a59f5fb1a78144d47"><div class="ttname"><a href="classlayers_1_1_layer.html#a918cc34c6ee46f2a59f5fb1a78144d47">layers::Layer::obatch_size</a></div><div class="ttdeci">int obatch_size</div><div class="ttdef"><b>Definition:</b> <a href="layers_8h_source.html#l00128">layers.h:128</a></div></div>
<div class="ttc" id="classnetwork_1_1seq_network_html_a3de3372e498824eec49453999adda7ad"><div class="ttname"><a href="classnetwork_1_1seq_network.html#a3de3372e498824eec49453999adda7ad">network::seqNetwork::blas_handle</a></div><div class="ttdeci">cublasHandle_t blas_handle</div><div class="ttdef"><b>Definition:</b> <a href="layers_8h_source.html#l00170">layers.h:170</a></div></div>
<div class="ttc" id="layers_8h_html_a89f66b9c8c2fec36a8bafc064cca64d0"><div class="ttname"><a href="layers_8h.html#a89f66b9c8c2fec36a8bafc064cca64d0">SoftmaxLossBackprop</a></div><div class="ttdeci">__global__ void SoftmaxLossBackprop(const int *label, int num_labels, int batch_size, float *diff)</div></div>
<div class="ttc" id="layers_8h_html_a97afc435921c1d3559b853bfd2eb0f82"><div class="ttname"><a href="layers_8h.html#a97afc435921c1d3559b853bfd2eb0f82">transposeNaive</a></div><div class="ttdeci">__global__ void transposeNaive(float *odata, const float *idata, int idata_rows, int idata_cols)</div></div>
<div class="ttc" id="layers_8h_html_a2527f5d1bfa5229f57083db0d82f54be"><div class="ttname"><a href="layers_8h.html#a2527f5d1bfa5229f57083db0d82f54be">padding_type</a></div><div class="ttdeci">padding_type</div><div class="ttdef"><b>Definition:</b> <a href="layers_8h_source.html#l00019">layers.h:19</a></div></div>
<div class="ttc" id="classlayers_1_1_layer_html_a72cbb8c4ac7c0238d43b93e24f4bfd1b"><div class="ttname"><a href="classlayers_1_1_layer.html#a72cbb8c4ac7c0238d43b93e24f4bfd1b">layers::Layer::owidth</a></div><div class="ttdeci">int owidth</div><div class="ttdef"><b>Definition:</b> <a href="layers_8h_source.html#l00131">layers.h:131</a></div></div>
<div class="ttc" id="classnetwork_1_1seq_network_html_a2823a8d660305acb891dedc2a3c71285"><div class="ttname"><a href="classnetwork_1_1seq_network.html#a2823a8d660305acb891dedc2a3c71285">network::seqNetwork::lr</a></div><div class="ttdeci">float lr</div><div class="ttdef"><b>Definition:</b> <a href="layers_8h_source.html#l00159">layers.h:159</a></div></div>
<div class="ttc" id="layers_8h_html_a2bb98fbee87212254c977e746e4596e1"><div class="ttname"><a href="layers_8h.html#a2bb98fbee87212254c977e746e4596e1">init_buffer_map</a></div><div class="ttdeci">std::map&lt; std::string, float * &gt; init_buffer_map()</div></div>
<div class="ttc" id="layers_8h_html_af73fa246eea18b9cf1297ec23452622b"><div class="ttname"><a href="layers_8h.html#af73fa246eea18b9cf1297ec23452622b">cublasGetErrorString</a></div><div class="ttdeci">const char * cublasGetErrorString(cublasStatus_t error)</div></div>
<div class="ttc" id="layers_8h_html_a7b854a420832e9f14150721344c72a3d"><div class="ttname"><a href="layers_8h.html#a7b854a420832e9f14150721344c72a3d">update</a></div><div class="ttdeci">__global__ void update(float *weights, float *grad, float lr, int N)</div></div>
<div class="ttc" id="classnetwork_1_1seq_network_html_ad44dd0adfaee158f52249851c8a4f314"><div class="ttname"><a href="classnetwork_1_1seq_network.html#ad44dd0adfaee158f52249851c8a4f314">network::seqNetwork::layer_buffer_bytes</a></div><div class="ttdeci">std::vector&lt; std::map&lt; std::string, int &gt; &gt; layer_buffer_bytes</div><div class="ttdef"><b>Definition:</b> <a href="layers_8h_source.html#l00164">layers.h:164</a></div></div>
<div class="ttc" id="layers_8h_html_ac1954f064bd25ef443e4f3fb9db90d88"><div class="ttname"><a href="layers_8h.html#ac1954f064bd25ef443e4f3fb9db90d88">matrixMultiplyShared</a></div><div class="ttdeci">__global__ void matrixMultiplyShared(float *A, float *B, float *C, int numARows, int numAColumns, int numBRows, int numBColumns, int numCRows, int numCColumns)</div></div>
<div class="ttc" id="classnetwork_1_1seq_network_html_a986bf55a752b11cb0b1dcffb137fd51f"><div class="ttname"><a href="classnetwork_1_1seq_network.html#a986bf55a752b11cb0b1dcffb137fd51f">network::seqNetwork::prefetch_trigger_layer_no_</a></div><div class="ttdeci">int prefetch_trigger_layer_no_</div><div class="ttdef"><b>Definition:</b> <a href="layers_8h_source.html#l00419">layers.h:419</a></div></div>
<div class="ttc" id="layers_8h_html_a2527f5d1bfa5229f57083db0d82f54beacf0713491d9b887eaccfd80c18abca47"><div class="ttname"><a href="layers_8h.html#a2527f5d1bfa5229f57083db0d82f54beacf0713491d9b887eaccfd80c18abca47">VALID</a></div><div class="ttdef"><b>Definition:</b> <a href="layers_8h_source.html#l00021">layers.h:21</a></div></div>
<div class="ttc" id="classnetwork_1_1seq_network_html_ac8aadabba842e81b7a94ec66488c7736"><div class="ttname"><a href="classnetwork_1_1seq_network.html#ac8aadabba842e81b7a94ec66488c7736">network::seqNetwork::layer_info</a></div><div class="ttdeci">std::vector&lt; std::vector&lt; std::string &gt; &gt; layer_info</div><div class="ttdef"><b>Definition:</b> <a href="layers_8h_source.html#l00161">layers.h:161</a></div></div>
<div class="ttc" id="classnetwork_1_1seq_network_html_a74c4bed65724ccec7d94d69e0f324f36"><div class="ttname"><a href="classnetwork_1_1seq_network.html#a74c4bed65724ccec7d94d69e0f324f36">network::seqNetwork::num_layers</a></div><div class="ttdeci">int num_layers</div><div class="ttdef"><b>Definition:</b> <a href="layers_8h_source.html#l00158">layers.h:158</a></div></div>
<div class="ttc" id="classlayers_1_1_layer_html_aed99be2a4243da8e825988407860ce10"><div class="ttname"><a href="classlayers_1_1_layer.html#aed99be2a4243da8e825988407860ce10">layers::Layer::iheight</a></div><div class="ttdeci">int iheight</div><div class="ttdef"><b>Definition:</b> <a href="layers_8h_source.html#l00134">layers.h:134</a></div></div>
<div class="ttc" id="classnetwork_1_1seq_network_html_a659234506728acfc3e30858479628400"><div class="ttname"><a href="classnetwork_1_1seq_network.html#a659234506728acfc3e30858479628400">network::seqNetwork::max_sub_batch_size_</a></div><div class="ttdeci">unsigned max_sub_batch_size_</div><div class="ttdef"><b>Definition:</b> <a href="layers_8h_source.html#l00407">layers.h:407</a></div></div>
<div class="ttc" id="layers_8h_html_ab3e90881a2476fd461eb2bcfcaa7cf63"><div class="ttname"><a href="layers_8h.html#ab3e90881a2476fd461eb2bcfcaa7cf63">gpuAssert</a></div><div class="ttdeci">void gpuAssert(cudaError_t code, const char *file, int line, bool abort=true)</div><div class="ttdef"><b>Definition:</b> <a href="layers_8h_source.html#l00057">layers.h:57</a></div></div>
<div class="ttc" id="classnetwork_1_1seq_network_html_acfcd17bf4969cb34706a26ddd212c2a8"><div class="ttname"><a href="classnetwork_1_1seq_network.html#acfcd17bf4969cb34706a26ddd212c2a8">network::seqNetwork::max_seqnet_memory_</a></div><div class="ttdeci">unsigned max_seqnet_memory_</div><div class="ttdef"><b>Definition:</b> <a href="layers_8h_source.html#l00415">layers.h:415</a></div></div>
<div class="ttc" id="layers_8h_html_ac752072214b57ad911f8b833effb67c1"><div class="ttname"><a href="layers_8h.html#ac752072214b57ad911f8b833effb67c1">transposeCoalesced</a></div><div class="ttdeci">__global__ void transposeCoalesced(float *odata, const float *idata, int idata_rows, int idata_cols)</div></div>
<div class="ttc" id="classnetwork_1_1seq_network_html_a4089a7cefb6d92210ed971a73c917990"><div class="ttname"><a href="classnetwork_1_1seq_network.html#a4089a7cefb6d92210ed971a73c917990">network::seqNetwork::sync_layer_no_</a></div><div class="ttdeci">int sync_layer_no_</div><div class="ttdef"><b>Definition:</b> <a href="layers_8h_source.html#l00418">layers.h:418</a></div></div>
<div class="ttc" id="layers_8h_html_a2527f5d1bfa5229f57083db0d82f54bea57316ad3090cf5cb9a92a3ec55dc18e9"><div class="ttname"><a href="layers_8h.html#a2527f5d1bfa5229f57083db0d82f54bea57316ad3090cf5cb9a92a3ec55dc18e9">SAME</a></div><div class="ttdef"><b>Definition:</b> <a href="layers_8h_source.html#l00020">layers.h:20</a></div></div>
<div class="ttc" id="classnetwork_1_1seq_network_html_a1c376b3bb31bba27bf259737148185f9"><div class="ttname"><a href="classnetwork_1_1seq_network.html#a1c376b3bb31bba27bf259737148185f9">network::seqNetwork::compute_stream_</a></div><div class="ttdeci">cudaStream_t compute_stream_</div><div class="ttdef"><b>Definition:</b> <a href="layers_8h_source.html#l00409">layers.h:409</a></div></div>
<div class="ttc" id="classnetwork_1_1seq_network_html_a2abaa80163ffc186247d3bb9fed64edc"><div class="ttname"><a href="classnetwork_1_1seq_network.html#a2abaa80163ffc186247d3bb9fed64edc">network::seqNetwork::batch_labels_</a></div><div class="ttdeci">int * batch_labels_</div><div class="ttdef"><b>Definition:</b> <a href="layers_8h_source.html#l00417">layers.h:417</a></div></div>
</div><!-- fragment --></div><!-- contents -->
<!-- start footer part -->
<hr class="footer"/><address class="footer"><small>
Generated on Wed Apr 22 2020 13:01:41 for MoDNN by &#160;<a href="http://www.doxygen.org/index.html">
<img class="footer" src="doxygen.png" alt="doxygen"/>
</a> 1.8.11
</small></address>
</body>
</html>
